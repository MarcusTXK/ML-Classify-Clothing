{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4acb7a-64dd-4107-9ee4-d0ee582724f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2 as cv\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imshow, imsave\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6dff234-7a99-4b49-88af-0a40d98ef085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import glob\n",
    "\n",
    "file = glob.glob('./clothing-dataset-small-master.zip')\n",
    "\n",
    "with zipfile.ZipFile(file[0], 'r') as zip_ref:\n",
    "    zip_ref.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f5491-21de-454f-ab7e-d7dcc901a7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data_type in [\"train\", \"validation\", \"test\"]:\n",
    "    folder_path = \"./data/clothing-dataset-small-master/\" + data_type\n",
    "    \n",
    "    # combine validation and train\n",
    "    new_folder_path = \"./data/clothing-dataset/\" + (\"test\" if data_type == \"test\" else \"train\")\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        new_path = os.path.join(new_folder_path, folder)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = Image.open(image_path)\n",
    "                new_image_path = os.path.join(new_folder_path, folder, filename)\n",
    "                img.save(new_image_path)\n",
    "                                              \n",
    "                # flip all images besides t-shirts to balance the data\n",
    "                if folder != \"t-shirt\":\n",
    "                    img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                    new_image_path = os.path.join(new_folder_path, folder, \"flipped_\" + filename)\n",
    "                    img.save(new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577498db-2c22-45a8-975d-95e6806d55ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate HOG data from above data\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset/\" + data_type\n",
    "    new_folder_path = \"./data/clothing-dataset-hog/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        new_path = os.path.join(new_folder_path, folder)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                img = cv.imread(image_path,cv.IMREAD_GRAYSCALE)\n",
    "                resized_img  = cv.resize(img, (64, 128),interpolation =cv.INTER_LINEAR)\n",
    "                fd, hog_image = hog(resized_img , orientations=9, pixels_per_cell=(8, 8), \n",
    "                    cells_per_block=(2, 2), visualize=True)\n",
    "                new_image_path = os.path.join(new_folder_path, folder, filename)\n",
    "                cv.imwrite(new_image_path, hog_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd88eab1-3b96-46c5-b42c-185e1e67903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: HOG\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "image = None\n",
    "count = 0\n",
    "for data_type in data_types:\n",
    "    folder_path = \"./data/clothing-dataset-hog/\" + data_type\n",
    "\n",
    "    for folder in os.listdir(folder_path):\n",
    "        for filename in os.listdir(os.path.join(folder_path, folder)):\n",
    "            # Open the image\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(folder_path, folder, filename)\n",
    "                image = imread(image_path)\n",
    "                result = np.array(image).ravel()\n",
    "                if data_type == \"test\":\n",
    "                    X_test.append(result)\n",
    "                    y_test.append(folder)\n",
    "                else:\n",
    "                    X_train.append(result)\n",
    "                    y_train.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d608ef-a4fe-4205-91f9-eeec0d87c15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# define the number of folds for cross validation\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "# define param search space for knn, dt, and rf\n",
    "knn_param_grid = {'n_neighbors': list(range(2, 100))}\n",
    "dt_param_grid = {'max_depth': list(range(2, 100))}\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': list(range(2, 100)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "svm_param_grid = {'svm__alpha': uniform(loc=0, scale=0.01), \n",
    "                  'svm__loss': ['hinge', 'squared_hinge'], \n",
    "                 'svm__penalty': ['l2', 'l1', 'elasticnet']}\n",
    "\n",
    "# define models\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier(max_features=512)\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# define scoring metric\n",
    "f1_scorer = make_scorer(f1_score, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0446c4-811f-4794-bb3d-4847852e8a00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Best k:  {'n_neighbors': 2}\n",
      "Best F1 score:  0.5890294874735581\n",
      "Test F1 Score:  0.44653179190751446\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn_model = RandomizedSearchCV(knn, knn_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, random_state=42)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"KNN:\")\n",
    "print(\"Best k: \", knn_model.best_params_)\n",
    "print(\"Best F1 score: \", knn_model.best_score_)\n",
    "\n",
    "knn_final = KNeighborsClassifier(n_neighbors=int(knn_model.best_params_['n_neighbors']))\n",
    "knn_final.fit(X_train, y_train)\n",
    "y_pred = knn_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3ae1cf-7328-4e18-9a80-952d753cbd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT:\n",
      "Best depth:  {'max_depth': 12}\n",
      "Best F1 score:  0.33238057615685873\n",
      "Test F1 Score:  0.315028901734104\n"
     ]
    }
   ],
   "source": [
    "# DT\n",
    "dt_model = RandomizedSearchCV(dt, dt_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"DT:\")\n",
    "print(\"Best depth: \", dt_model.best_params_)\n",
    "print(\"Best F1 score: \", dt_model.best_score_)\n",
    "\n",
    "dt_final = DecisionTreeClassifier(max_depth=int(dt_model.best_params_['max_depth']), max_features=512)\n",
    "dt_final.fit(X_train, y_train)\n",
    "y_pred = dt_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31240f3-65ad-4173-b565-541e3a2b0d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Best parameters:  {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 74}\n",
      "Best F1 score:  0.579101075232278\n",
      "Test F1 Score:  0.4884393063583815\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (RF)\n",
    "rf_model = RandomizedSearchCV(rf, rf_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(\"Best parameters: \", rf_model.best_params_)\n",
    "print(\"Best F1 score: \", rf_model.best_score_)\n",
    "\n",
    "rf_final = RandomForestClassifier(**rf_model.best_params_)\n",
    "rf_final.fit(X_train, y_train)\n",
    "y_pred_rf = rf_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred_rf, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0dc30f-255e-4cc7-b19d-df305fc3f58c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:705: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Best params:  {'svm__alpha': 0.003745401188473625, 'svm__loss': 'hinge', 'svm__penalty': 'elasticnet'}\n",
      "Best F1 score:  0.6186484978747384\n",
      "Test F1 Score:  0.569364161849711\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# SVM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SGDClassifier())\n",
    "])\n",
    "\n",
    "svm_model = RandomizedSearchCV(pipeline, svm_param_grid, cv=NUM_FOLDS, scoring=f1_scorer, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"Best params: \", svm_model.best_params_)\n",
    "print(\"Best F1 score: \", svm_model.best_score_)\n",
    "\n",
    "svm_final = make_pipeline(StandardScaler(), SGDClassifier(alpha=svm_model.best_params_['svm__alpha'], loss=svm_model.best_params_['svm__loss'], penalty=svm_model.best_params_['svm__penalty']))\n",
    "svm_final.fit(X_train, y_train)\n",
    "y_pred = svm_final.predict(X_test)\n",
    "print(\"Test F1 Score: \", f1_score(y_test, y_pred, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccdbb03-4adc-4de3-82fe-c3c99d22bdee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
